"""
Milvus æœåŠ¡æ¨¡å— (æœ€ç»ˆä¿®å¤ç‰ˆ)
åŠŸèƒ½ï¼š
1. é€‚é… app_improved.py çš„è°ƒç”¨
2. è‡ªåŠ¨å¤„ç† 512ç»´ -> 384ç»´ çš„åˆ‡æ¢ (è‡ªåŠ¨é‡å»ºåº“)
3. è§£å†³ 'str' object has no attribute 'insert' æŠ¥é”™
"""
import streamlit as st
from pymilvus import connections, utility, Collection, FieldSchema, CollectionSchema, DataType
import time

def get_milvus_client(data_path: str):
    """
    å»ºç«‹ Milvus è¿æ¥ (åº•å±‚æ¥å£)
    """
    try:
        # 1. å°è¯•æ–­å¼€æ—§è¿æ¥ï¼Œé˜²æ­¢ Streamlit é‡è½½æ—¶æŠ¥é”™
        try:
            connections.disconnect("default")
        except Exception:
            pass

        # 2. è§£æ IP (å»æ‰ http://)
        host = "127.0.0.1"
        port = "19530"
        
        # ç®€å•çš„æ¸…æ´—é€»è¾‘
        if "://" in data_path:
            clean_path = data_path.split("://")[-1]
            if ":" in clean_path:
                host = clean_path.split(":")[0]
        elif ":" in data_path:
            host = data_path.split(":")[0]

        print(f"ğŸ”Œ [Milvus] æ­£åœ¨è¿æ¥ {host}:{port}...")
        connections.connect(alias="default", host=host, port=port, timeout=5)
        
        return "default" # è¿”å›è¿æ¥åˆ«åï¼Œä¸æ˜¯å¯¹è±¡
    except Exception as e:
        st.error(f"Milvus è¿æ¥å¤±è´¥: {e}")
        return None

def setup_milvus_collection(client, config):
    """
    åˆå§‹åŒ–é›†åˆ (è‡ªåŠ¨æ£€æµ‹ç»´åº¦å†²çª)
    """
    if not client:
        return False
    
    collection_name = config.milvus.collection_name
    target_dim = config.model.embedding_dim # ä» config è¯»å– (384)
    
    try:
        # 1. æ£€æŸ¥æ˜¯å¦å­˜åœ¨
        if utility.has_collection(collection_name):
            col = Collection(collection_name)
            col.load()
            
            # 2. æ·±åº¦æ£€æŸ¥ï¼šç»´åº¦æ˜¯å¦åŒ¹é…ï¼Ÿ
            existing_dim = -1
            for field in col.schema.fields:
                if field.name == "embedding":
                    existing_dim = field.params.get('dim')
                    break
            
            # å¦‚æœ Config æ˜¯ 384ï¼Œä½†åº“é‡Œæ˜¯ 512ï¼Œå¿…é¡»åˆ åº“é‡å»ºï¼
            if existing_dim != -1 and existing_dim != target_dim:
                st.warning(f"âš ï¸ ç»´åº¦å†²çªæ£€æµ‹ï¼æ•°æ®åº“: {existing_dim}ç»´ vs é…ç½®: {target_dim}ç»´")
                st.warning(f"ğŸ”„ æ­£åœ¨è‡ªåŠ¨åˆ é™¤æ—§é›†åˆ '{collection_name}' å¹¶é‡å»º...")
                utility.drop_collection(collection_name)
                # åˆ å®Œåï¼Œç¨‹åºä¼šç»§ç»­å¾€ä¸‹èµ°å»åˆ›å»ºæ–°çš„
            else:
                print(f"ğŸ“¦ [Milvus] é›†åˆå·²å°±ç»ª: {collection_name}")
                return True

        # 3. åˆ›å»ºæ–°é›†åˆ
        st.info(f"ğŸ”¨ åˆ›å»ºæ–°é›†åˆ: {collection_name} (Dim={target_dim})")
        
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=target_dim),
            # ã€é‡è¦ã€‘å¢åŠ é•¿åº¦ä»¥å®¹çº³å®Œæ•´æ–‡ç« 
            FieldSchema(name="content_preview", dtype=DataType.VARCHAR, max_length=10000)
        ]
        schema = CollectionSchema(fields, description="Medical RAG Data")
        col = Collection(collection_name, schema)
        
        # åˆ›å»ºç´¢å¼•
        index_params = {
            "metric_type": config.milvus.index_metric_type,
            "index_type": config.milvus.index_type,
            "params": config.milvus.index_params
        }
        col.create_index(field_name="embedding", index_params=index_params)
        col.load()
        st.success("âœ… é›†åˆåˆå§‹åŒ–æˆåŠŸ")
        return True

    except Exception as e:
        st.error(f"é›†åˆåˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def index_data_incremental(client, data, embedding_model, db, config):
    """
    å¢é‡ç´¢å¼• (UI æŒ‰é’®ç‚¹å‡»åæ‰§è¡Œçš„é€»è¾‘)
    """
    if not client or not embedding_model:
        st.error("æœåŠ¡æœªå°±ç»ª")
        return False
    
    collection_name = config.milvus.collection_name
    
    # 1. è·å–å·²ç´¢å¼• ID
    indexed_ids = set(db.get_indexed_doc_ids())
    
    docs_to_process = []
    texts_to_embed = []
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0, text="æ­£åœ¨åˆ†ææ•°æ®...")
    
    # 2. ç­›é€‰
    limit = config.data.max_articles_to_index
    for i, doc in enumerate(data):
        if i >= limit: break
        
        doc_id = doc.get('chunk_index', i)
        
        # è¿™é‡Œçš„ abstract å…¶å®æ˜¯å…¨æ–‡ (ç”± convert è„šæœ¬ä¿è¯)
        content = doc.get('abstract', '')
        title = doc.get('title', 'No Title')
        
        # æ— è®ºæ˜¯å¦å·²ç´¢å¼•ï¼Œå…ˆå­˜å…¥ SQLite ç¡®ä¿å…ƒæ•°æ®å®Œæ•´
        # (å› ä¸ºä¹‹å‰å¯èƒ½è¢«æ¸…ç©ºè¿‡)
        db.add_document(doc_id, title, content, content, doc.get('source_file'), i)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é‡åŒ– (Milvus)
        if doc_id in indexed_ids:
            continue
            
        full_text = f"Title: {title}\nContent: {content}"
        
        docs_to_process.append({
            "id": doc_id,
            "preview": full_text[:9999] # æˆªæ–­é˜²æ­¢è¶…é•¿æŠ¥é”™
        })
        texts_to_embed.append(full_text)

    # 3. å¦‚æœæ²¡æ–°æ•°æ®
    if not docs_to_process:
        progress_bar.progress(1.0, text="âœ… æ•°æ®å·²æ˜¯æœ€æ–°ã€‚")
        time.sleep(1)
        progress_bar.empty()
        return True
    
    st.info(f"å‘ç° {len(docs_to_process)} æ¡æ•°æ®å¾…ç´¢å¼•...")
    
    try:
        # 4. æ‰¹é‡å¤„ç†
        batch_size = 50
        col = Collection(collection_name) # è·å–é›†åˆå¯¹è±¡
        
        total = len(docs_to_process)
        for i in range(0, total, batch_size):
            batch_docs = docs_to_process[i : i + batch_size]
            batch_texts = texts_to_embed[i : i + batch_size]
            
            # è¿›åº¦
            progress = i / total
            progress_bar.progress(progress, text=f"æ­£åœ¨å‘é‡åŒ– {i}/{total}...")
            
            # Embedding
            embeddings = embedding_model.encode(batch_texts, normalize_embeddings=True)
            
            # Insert
            ids_col = [d['id'] for d in batch_docs]
            embeds_col = embeddings.tolist()
            previews_col = [d['preview'] for d in batch_docs]
            
            col.insert([ids_col, embeds_col, previews_col])
            
            # Update SQLite
            for d in batch_docs:
                db.mark_indexed(d['id'])

        # 5. æ”¶å°¾ï¼šå¼ºåˆ¶è½ç›˜
        progress_bar.progress(0.9, text="æ­£åœ¨ä¿å­˜æ•°æ® (Flush)...")
        col.flush()
        
        progress_bar.progress(1.0, text="âœ… ç´¢å¼•å®Œæˆï¼")
        st.success(f"æˆåŠŸç´¢å¼• {total} æ¡æ–‡æ¡£ã€‚")
        time.sleep(2)
        progress_bar.empty()
        return True
        
    except Exception as e:
        st.error(f"ç´¢å¼•å‡ºé”™: {e}")
        return False